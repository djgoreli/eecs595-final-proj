{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       TEXT DIAGNOSIS\n",
      "ROW_ID_x                                                             \n",
      "21        admission date discharge date date of birth se...     Other\n",
      "21        normal sinus rhythm nondiagnostic repolarizati...     Other\n",
      "21        normal sinus rhythm without diagnostic abnorma...     Other\n",
      "21         pm chest portable ap clip clip number radiolo...     Other\n",
      "21         am ct head wo contrast clip clip number radio...     Other\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "train_file = 'MIMIC_III_train.csv'\n",
    "test_file = 'MIMIC_III_test.csv'\n",
    "validation_file = 'MIMIC_III_validation.csv'\n",
    "\n",
    "train = pd.read_csv(train_file, index_col=0)\n",
    "test = pd.read_csv(test_file, index_col=0)\n",
    "validation = pd.read_csv(validation_file, index_col=0)\n",
    "\n",
    "# Remove all columns except for TEXT and DIAGNOSIS\n",
    "train = train[['TEXT', 'DIAGNOSIS']]\n",
    "test = test[['TEXT', 'DIAGNOSIS']]\n",
    "validation = validation[['TEXT', 'DIAGNOSIS']]\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove all non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text, re.I|re.A)\n",
    "    # Remove all numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove all single characters\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    # Converting to Lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "\n",
    "train['TEXT'] = train['TEXT'].apply(preprocess)\n",
    "test['TEXT'] = test['TEXT'].apply(preprocess)\n",
    "validation['TEXT'] = validation['TEXT'].apply(preprocess)\n",
    "\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 12:35:06.293533: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 12:35:06.401850: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-20 12:35:06.401904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-20 12:35:06.404772: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-20 12:35:06.419486: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-20 12:35:06.420709: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 12:35:08.254707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60530 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train['TEXT'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data tensor: (30000, 250)\n",
      "Shape of test data tensor: (10000, 250)\n",
      "Shape of validation data tensor: (15000, 250)\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences\n",
    "\n",
    "# Train\n",
    "X_train = tokenizer.texts_to_sequences(train['TEXT'].values)\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of train data tensor:', X_train.shape)\n",
    "\n",
    "# Test\n",
    "X_test = tokenizer.texts_to_sequences(test['TEXT'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of test data tensor:', X_test.shape)\n",
    "\n",
    "# Validation\n",
    "X_validation = tokenizer.texts_to_sequences(validation['TEXT'].values)\n",
    "X_validation = pad_sequences(X_validation, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of validation data tensor:', X_validation.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train label tensor: (30000, 11)\n",
      "Shape of test label tensor: (10000, 11)\n",
      "Shape of validation label tensor: (15000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical labels to numbers\n",
    "Y_train = pd.get_dummies(train['DIAGNOSIS']).values\n",
    "print('Shape of train label tensor:', Y_train.shape)\n",
    "\n",
    "Y_test = pd.get_dummies(test['DIAGNOSIS']).values\n",
    "print('Shape of test label tensor:', Y_test.shape)\n",
    "\n",
    "Y_validation = pd.get_dummies(validation['DIAGNOSIS']).values\n",
    "print('Shape of validation label tensor:', Y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABDOMINAL PAIN': 522, 'ALTERED MENTAL STATUS': 327, 'CHEST PAIN': 77, 'CONGESTIVE HEART FAILURE': 419, 'CORONARY ARTERY DISEASE': 476, 'FEVER': 92, 'INTRACRANIAL HEMORRHAGE': 36, 'NEWBORN': 9573, 'Other': 17129, 'PNEUMONIA': 653, 'SEPSIS': 696}\n"
     ]
    }
   ],
   "source": [
    "# Print proportions of each class\n",
    "import numpy as np\n",
    "unique, counts = np.unique(train['DIAGNOSIS'], return_counts=True)\n",
    "total = sum(counts)\n",
    "print(dict(zip(unique, counts/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 12:41:29.606316: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-20 12:41:29.609044: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 299s 622ms/step - loss: 0.7846 - accuracy: 0.7960 - val_loss: 0.7585 - val_accuracy: 0.8283\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 371s 790ms/step - loss: 0.7761 - accuracy: 0.8065 - val_loss: 0.7490 - val_accuracy: 0.8305\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 421s 898ms/step - loss: 0.5819 - accuracy: 0.8655 - val_loss: 0.7767 - val_accuracy: 0.8238\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 360s 768ms/step - loss: 0.5273 - accuracy: 0.8735 - val_loss: 0.7748 - val_accuracy: 0.8299\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 390s 831ms/step - loss: 0.4705 - accuracy: 0.8829 - val_loss: 0.8470 - val_accuracy: 0.8262\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(Y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_validation, Y_validation), callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 29s 94ms/step - loss: 0.8090 - accuracy: 0.8438\n",
      "Test set\n",
      "  Loss: 0.809\n",
      "  Accuracy: 0.844\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "accr = model.evaluate(X_test, Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0], accr[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
